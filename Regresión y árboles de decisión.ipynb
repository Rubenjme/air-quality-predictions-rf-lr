{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal y árboles de decisión para tareas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "Se pretende poner en práctica los pasos para la resolución de un problema de machine learning, el tratamiento de datos y la creación de modelos basados en regresión lineal y árboles de decisión. El objetivo es entender de forma práctica con un problema las diferencias que existen a la hora de entrenar los diferentes modelos.\n",
    "\n",
    "- Realizar un Análisis Exploratorio de Datos (EDA).\n",
    "- Entender y aplicar los conceptos de la Regresión Lineal Múltiple a un problema de regresión.\n",
    "- Entender y aplicar los conceptos de Árboles de Decisión a un problema de regresión.\n",
    "- Evaluar y analizar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del proyecto\n",
    "\n",
    "El conjunto de datos con el que se va a trabajar se encuentra en el siguiente enlace: https://archive.ics.uci.edu/dataset/360/air+quality\n",
    "\n",
    "Se trata de un dataset con un conjunto de datos sobre calidad del aire. El conjunto de datos contiene 9358 instancias de respuestas promediadas por hora de una matriz de 5 sensores químicos de óxido de metal integrados en un dispositivo multisensor químico de calidad del aire. El dispositivo estaba ubicado en un área significativamente contaminada, al nivel de la carretera, dentro de una ciudad italiana. Los datos se registraron desde marzo de 2004 hasta febrero de 2005.\n",
    "\n",
    "El objetivo de la regresión será predecir la calidad del aire para un determinado día."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Análisis descriptivo de los datos\n",
    "\n",
    "Con este análisis se busca explorar, resumir y visualizar los datos para comprender su estructura, patrones y características principales antes de aplicar cualquier modelo de aprendizaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carga del dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('air+quality/AirQualityUCI.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cuántas instancias tiene el dataset? ¿Hay valores nulos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin depurar tiene 9471 instancias.\n",
      "__________________________________________\n",
      "Date              114\n",
      "Time              114\n",
      "CO(GT)            114\n",
      "PT08.S1(CO)       114\n",
      "NMHC(GT)          114\n",
      "C6H6(GT)          114\n",
      "PT08.S2(NMHC)     114\n",
      "NOx(GT)           114\n",
      "PT08.S3(NOx)      114\n",
      "NO2(GT)           114\n",
      "PT08.S4(NO2)      114\n",
      "PT08.S5(O3)       114\n",
      "T                 114\n",
      "RH                114\n",
      "AH                114\n",
      "Unnamed: 15      9471\n",
      "Unnamed: 16      9471\n",
      "dtype: int64\n",
      "__________________________________________\n",
      "Date             0\n",
      "Time             0\n",
      "CO(GT)           0\n",
      "PT08.S1(CO)      0\n",
      "NMHC(GT)         0\n",
      "C6H6(GT)         0\n",
      "PT08.S2(NMHC)    0\n",
      "NOx(GT)          0\n",
      "PT08.S3(NOx)     0\n",
      "NO2(GT)          0\n",
      "PT08.S4(NO2)     0\n",
      "PT08.S5(O3)      0\n",
      "T                0\n",
      "RH               0\n",
      "AH               0\n",
      "dtype: int64\n",
      "__________________________________________\n",
      "Depurado tiene 9357 instancias.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_instancias = dataset.shape[0]\n",
    "print(f\"Sin depurar tiene {n_instancias} instancias.\") #Aparecen 9471 instancias\n",
    "print('_' * 42)\n",
    "\n",
    "print(dataset.isnull().sum()) #Nulos por columna\n",
    "print('_' * 42)\n",
    "\n",
    "dataset.dropna(subset=['Date'], inplace=True)\n",
    "dataset.drop(columns=['Unnamed: 15', 'Unnamed: 16'], inplace=True)\n",
    "n_instancias = dataset.shape[0]\n",
    "\n",
    "print(dataset.isnull().sum()) #Números de nulos por columna\n",
    "print('_' * 42)\n",
    "print(f\"Depurado tiene {n_instancias} instancias.\") #Aparecen 9357 instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra que hay 9471 instancias, lo cuál no coincide con lo indicado en la descripción del dataset.\n",
    "\n",
    "Tras revisarlo se observa que hay que hacer un proceso de depuración de los datos debido a que:\n",
    " - Las columnas 15 y 16 no tienen datos.\n",
    " - Hay 114 filas nulas.\n",
    "\n",
    "Decido eliminar aquellas en las que 'Date' tiene valores nulos, aunque hubiera servido cualquier otra variable realmente, ya que son filas completamente vacías. Además elimino las columnas 15 y 16 cuyos valores son todos nulos.\n",
    "Tras depurar el dataset aparecen <b> 9357 instancias </b> que si coincide con lo indicado en la descripción de la web del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cuál es el tipo de datos de cada una de las columnas? ¿Cuántas columnas categóricas hay? ¿Cuántas continuas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9357 entries, 0 to 9356\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           9357 non-null   object \n",
      " 1   Time           9357 non-null   object \n",
      " 2   CO(GT)         9357 non-null   object \n",
      " 3   PT08.S1(CO)    9357 non-null   float64\n",
      " 4   NMHC(GT)       9357 non-null   float64\n",
      " 5   C6H6(GT)       9357 non-null   object \n",
      " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
      " 7   NOx(GT)        9357 non-null   float64\n",
      " 8   PT08.S3(NOx)   9357 non-null   float64\n",
      " 9   NO2(GT)        9357 non-null   float64\n",
      " 10  PT08.S4(NO2)   9357 non-null   float64\n",
      " 11  PT08.S5(O3)    9357 non-null   float64\n",
      " 12  T              9357 non-null   object \n",
      " 13  RH             9357 non-null   object \n",
      " 14  AH             9357 non-null   object \n",
      "dtypes: float64(8), object(7)\n",
      "memory usage: 1.1+ MB\n",
      "__________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9357 entries, 0 to 9356\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           9357 non-null   object \n",
      " 1   Time           9357 non-null   object \n",
      " 2   CO(GT)         9357 non-null   float64\n",
      " 3   PT08.S1(CO)    9357 non-null   float64\n",
      " 4   NMHC(GT)       9357 non-null   float64\n",
      " 5   C6H6(GT)       9357 non-null   float64\n",
      " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
      " 7   NOx(GT)        9357 non-null   float64\n",
      " 8   PT08.S3(NOx)   9357 non-null   float64\n",
      " 9   NO2(GT)        9357 non-null   float64\n",
      " 10  PT08.S4(NO2)   9357 non-null   float64\n",
      " 11  PT08.S5(O3)    9357 non-null   float64\n",
      " 12  T              9357 non-null   float64\n",
      " 13  RH             9357 non-null   float64\n",
      " 14  AH             9357 non-null   float64\n",
      "dtypes: float64(13), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info() #Tipos de datos sin depurar\n",
    "print('_' * 42)\n",
    "\n",
    "conv_colum = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH']\n",
    "dataset[conv_colum] = dataset[conv_colum].replace(',', '.', regex=True).astype(float)\n",
    "\n",
    "dataset.info() #Tipos de datos depurados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que las columnas son de tipo object y float, aunque revisando el dataset, las columnas 'CO(GT)', 'C6H6(GT)', 'T', 'RH' y 'AH' no tiene mucho sentido que sean de tipo object y deberían ser de tipo float ya que son resultados númericos, esto se debe a que sus números decimales están separados por comas en lugar de punto, por lo que no se interpretarán correctamente, por ello realizo la transformación.\n",
    "\n",
    "Cómo se vió con el comando anterior:\n",
    "- Sin depurar el dataset, hay 7 columnas categóricas (tipo object) y 8 continuas (tipo float).\n",
    "- Una vez depurado se obtienen 2 columnas categóricas (tipo object) y 13 continuas (tipo float)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Existen valores anómalos en el dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0\n",
      "Time             0\n",
      "CO(GT)           0\n",
      "PT08.S1(CO)      0\n",
      "NMHC(GT)         0\n",
      "C6H6(GT)         0\n",
      "PT08.S2(NMHC)    0\n",
      "NOx(GT)          0\n",
      "PT08.S3(NOx)     0\n",
      "NO2(GT)          0\n",
      "PT08.S4(NO2)     0\n",
      "PT08.S5(O3)      0\n",
      "T                0\n",
      "RH               0\n",
      "AH               0\n",
      "dtype: int64\n",
      "__________________________________________\n",
      "Date                0\n",
      "Time                0\n",
      "CO(GT)           1683\n",
      "PT08.S1(CO)       366\n",
      "NMHC(GT)         8443\n",
      "C6H6(GT)          366\n",
      "PT08.S2(NMHC)     366\n",
      "NOx(GT)          1639\n",
      "PT08.S3(NOx)      366\n",
      "NO2(GT)          1642\n",
      "PT08.S4(NO2)      366\n",
      "PT08.S5(O3)       366\n",
      "T                 366\n",
      "RH                366\n",
      "AH                366\n",
      "dtype: int64\n",
      "__________________________________________\n",
      "Date             0\n",
      "Time             0\n",
      "CO(GT)           0\n",
      "PT08.S1(CO)      0\n",
      "NMHC(GT)         0\n",
      "C6H6(GT)         0\n",
      "PT08.S2(NMHC)    0\n",
      "NOx(GT)          0\n",
      "PT08.S3(NOx)     0\n",
      "NO2(GT)          0\n",
      "PT08.S4(NO2)     0\n",
      "PT08.S5(O3)      0\n",
      "T                0\n",
      "RH               0\n",
      "AH               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_values = dataset.isnull().sum() #Confirmo que no hay nulos, debido a los cambios hechos anteriormente.\n",
    "print(null_values)\n",
    "print('_' * 42)\n",
    "\n",
    "dataset.replace(-200, np.nan, inplace=True) #Reemplazo los '-200' por NaN\n",
    "null_values = dataset.isnull().sum()\n",
    "print(null_values)\n",
    "print('_' * 42)\n",
    "\n",
    "num_col = dataset.select_dtypes(include=[np.number]).columns\n",
    "dataset[num_col] = dataset[num_col].fillna(dataset[num_col].mean()) #Cambio los NaN por la media de esa variable.\n",
    "null_values = dataset.isnull().sum()\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmo que tras los arreglos que hice anteriormente no hay ningún valor nulo en el dataset, pero según la descripción del mismo en la web hay valores etiquetados como '-200' que indican valores faltantes, los sustituyo por NaN para después sustituirlos por la media de esa variable para tener una ligera aproximación de esos datos.\n",
    "\n",
    "Aunque se observa que para NMHC, especialmente, faltan la mayoría de valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
